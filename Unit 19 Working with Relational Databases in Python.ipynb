{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt24TAEBJf9pcx56oCzZ8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namozhdehi/DataScience/blob/main/Unit%2019%20Working%20with%20Relational%20Databases%20in%20Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unit 19**\n",
        "\n",
        "# **Working with Relational Databases in Python**"
      ],
      "metadata": {
        "id": "3A7AUJ-Us4EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IPython magic command ! ls will display the contents of your current directory.\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zbFCL2Lt2k2",
        "outputId": "49fbc053-3b34-4130-b0e1-913e900395b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "moby_dick.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open a file: file\n",
        "file = open('moby_dick.txt', mode = 'r')\n",
        "\n",
        "# Print it\n",
        "print(file.read())\n",
        "\n",
        "# Check whether file is closed\n",
        "print(file.closed)\n",
        "\n",
        "# Close file\n",
        "file.close()\n",
        "\n",
        "# Check whether file is closed\n",
        "print(file.closed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3DHuxHi3zyp",
        "outputId": "82ae5c58-18fa-453b-b051-6c81ac430752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER 1. Loomings.\n",
            "\n",
            "Call me Ishmael. Some years ago--never mind how long precisely--having\n",
            "little or no money in my purse, and nothing particular to interest me on\n",
            "shore, I thought I would sail about a little and see the watery part of\n",
            "the world. It is a way I have of driving off the spleen and regulating\n",
            "the circulation. Whenever I find myself growing grim about the mouth;\n",
            "whenever it is a damp, drizzly November in my soul; whenever I find\n",
            "myself involuntarily pausing before coffin warehouses, and bringing up\n",
            "the rear of every funeral I meet; and especially whenever my hypos get\n",
            "such an upper hand of me, that it requires a strong moral principle to\n",
            "prevent me from deliberately stepping into the street, and methodically\n",
            "knocking people's hats off--then, I account it high time to get to sea\n",
            "as soon as I can. This is my substitute for pistol and ball. With a\n",
            "philosophical flourish Cato throws himself upon his sword; I quietly\n",
            "take to the ship. There is nothing surprising in this. If they but knew\n",
            "it, almost all men in their degree, some time or other, cherish very\n",
            "nearly the same feelings towards the ocean with me.\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read & print the first 3 lines\n",
        "with open('moby_dick.txt') as file:\n",
        "    print(file.readline())\n",
        "    print(file.readline())\n",
        "    print(file.readline())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3JqdjyM5C24",
        "outputId": "04825ef1-c5e6-4077-a0e4-9c8390ba2fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER 1. Loomings.\n",
            "\n",
            "\n",
            "\n",
            "Call me Ishmael. Some years ago--never mind how long precisely--having\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import package\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "\n",
        "# Assign filename to variable: file\n",
        "file = 'digits.csv'\n",
        "\n",
        "# Load file as array: digits\n",
        "digits = np.loadtxt(file, delimiter=',')\n",
        "\n",
        "# Print datatype of digits\n",
        "print(type(digits))\n",
        "\n",
        "# Select and reshape a row\n",
        "im = digits[21, 1:]\n",
        "im_sq = np.reshape(im, (28, 28))\n",
        "\n",
        "# Plot reshaped data (matplotlib.pyplot already loaded as plt)\n",
        "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aGYXXo9h9r7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'digits_header.txt'\n",
        "\n",
        "# Load the data: data\n",
        "data = np.loadtxt(file, delimiter='\\t', skiprows=1, usecols=[0,2])\n",
        "\n",
        "# Print data\n",
        "print(data)\n"
      ],
      "metadata": {
        "id": "C7ggUD0P5NS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign filename: file\n",
        "file = 'seaslug.txt'\n",
        "\n",
        "# Import file: data\n",
        "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
        "\n",
        "# Print the first element of data\n",
        "print(data[0])\n",
        "\n",
        "# Import data as floats and skip the first row: data_float\n",
        "data_float = np.loadtxt(file, delimiter='\\t', dtype=float, skiprows=1)\n",
        "\n",
        "# Print the 10th element of data_float\n",
        "print(data_float[9])\n",
        "\n",
        "# Plot a scatterplot of the data\n",
        "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
        "plt.xlabel('time (min.)')\n",
        "plt.ylabel('percentage of larvae')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5yy-kprN5NPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the filename: file\n",
        "file = 'titanic.csv'\n",
        "\n",
        "# Import file using np.recfromcsv: d\n",
        "d = np.recfromcsv(file, delimiter=',', dtype=None, names=True)\n",
        "\n",
        "# Print out first three entries of d\n",
        "print(d[:3])\n"
      ],
      "metadata": {
        "id": "aAPGLeaP5NMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas as pd\n",
        "import pandas as pd\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'titanic.csv'\n",
        "\n",
        "# Read the file into a DataFrame: df\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "# View the head of the DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "aNIfAdtx-YxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the filename: file\n",
        "file = 'digits.csv'\n",
        "\n",
        "# Read the first 5 rows of the file into a DataFrame: data\n",
        "data = pd.read_csv(file, header=None, nrows=5)\n",
        "\n",
        "# Build a numpy array from the DataFrame: data_array\n",
        "data_array = data.to_numpy()\n",
        "\n",
        "# Print the datatype of data_array to the shell\n",
        "print(type(data_array))"
      ],
      "metadata": {
        "id": "fMa-5yZy-Ypo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assign filename: file\n",
        "file = 'titanic_corrupt.txt'\n",
        "\n",
        "# Import file: data\n",
        "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')\n",
        "\n",
        "# Print the head of the DataFrame\n",
        "print(data.head())\n",
        "\n",
        "# Plot 'Age' variable in a histogram\n",
        "pd.DataFrame.hist(data[['Age']])\n",
        "plt.xlabel('Age (years)')\n",
        "plt.ylabel('count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zt3QseEA-Yhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pickle package\n",
        "import pickle\n",
        "\n",
        "# Open pickle file and load data: d\n",
        "with open('data.pkl', 'rb') as file:\n",
        "    d = pickle.load(file)\n",
        "\n",
        "# Print d\n",
        "print(d)\n",
        "\n",
        "# Print datatype of d\n",
        "print(type(d))"
      ],
      "metadata": {
        "id": "YTrZlSZHEmqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Assign spreadsheet filename: file\n",
        "file = 'battledeath.xlsx'\n",
        "\n",
        "# Load spreadsheet: xls\n",
        "xls = pd.ExcelFile(file)\n",
        "\n",
        "# Print sheet names\n",
        "print(xls.sheet_names)\n"
      ],
      "metadata": {
        "id": "Lii9X9tfGAYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sheet into a DataFrame by name: df1\n",
        "df1 = xls.parse('2004')\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Load a sheet into a DataFrame by index: df2\n",
        "df2 = xls.parse(0)\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())"
      ],
      "metadata": {
        "id": "tBYR4T9WGAGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse the first sheet and rename the columns: df1\n",
        "df1 = xls.parse(0, skiprows=[0], names=['Country', 'AAM due to War (2002)'])\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Parse the first column of the second sheet and rename the column: df2\n",
        "df2 = xls.parse(1, usecols=[0], skiprows=[1], names= ['Country'])\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())\n"
      ],
      "metadata": {
        "id": "deeZkMuaEmaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing SAS/Stata files using pandas"
      ],
      "metadata": {
        "id": "cyM-SnwMFjGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import sas7bdat package\n",
        "from sas7bdat import SAS7BDAT\n",
        "\n",
        "# Save file to a DataFrame: df_sas\n",
        "with SAS7BDAT('sales.sas7bdat') as file:\n",
        "    df_sas = file.to_data_frame()\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df_sas.head())\n",
        "\n",
        "# Plot histogram of DataFrame features (pandas and pyplot already imported)\n",
        "pd.DataFrame.hist(df_sas[['P']])\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZmXiGOR4LMjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load Stata file into a pandas DataFrame: df\n",
        "df = pd.read_stata('disarea.dta')\n",
        "\n",
        "# Print the head of the DataFrame df\n",
        "print(df.head())\n",
        "\n",
        "# Plot histogram of one column of the DataFrame\n",
        "pd.DataFrame.hist(df[['disa10']])\n",
        "plt.xlabel('Extent of disease')\n",
        "plt.ylabel('Number of countries')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "INKgOXAfLMcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing HDF5 files"
      ],
      "metadata": {
        "id": "iQk-lBrugd-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "# Assign filename: file\n",
        "file = 'LIGO_data.hdf5'\n",
        "\n",
        "# Load file: data\n",
        "data = h5py.File(file, 'r')\n",
        "\n",
        "# Print the datatype of the loaded file\n",
        "print(type(data))\n",
        "\n",
        "# Print the keys of the file\n",
        "for key in data.keys():\n",
        "    print(key)"
      ],
      "metadata": {
        "id": "GEJuFCiZLMWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the HDF5 group: group\n",
        "group = data['strain']\n",
        "\n",
        "# Check out keys of group\n",
        "for key in group.keys():\n",
        "    print(key)\n",
        "\n",
        "# Set variable equal to time series data: strain\n",
        "strain = data['strain']['Strain']\n",
        "\n",
        "# Set number of time points to sample: num_samples\n",
        "num_samples = 10000\n",
        "\n",
        "# Set time vector\n",
        "time = np.arange(0, 1, 1/num_samples)\n",
        "\n",
        "# Plot data\n",
        "plt.plot(time, strain[:num_samples])\n",
        "plt.xlabel('GPS Time (s)')\n",
        "plt.ylabel('strain')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jkG-ZvDoLMSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the HDF5 group: group\n",
        "group = data['strain']\n",
        "\n",
        "# Check out keys of group\n",
        "for key in group.keys():\n",
        "    print(key)\n",
        "\n",
        "# Set variable equal to time series data: strain\n",
        "strain = group['Strain'][:]\n",
        "\n",
        "# Set number of time points to sample: num_samples\n",
        "num_samples = 10000\n",
        "\n",
        "# Set time vector\n",
        "time = np.arange(0, 1, 1/num_samples)\n",
        "\n",
        "# Plot data\n",
        "plt.plot(time, strain[:num_samples])\n",
        "plt.xlabel('GPS Time (s)')\n",
        "plt.ylabel('strain')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kJaFA0imjJZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing MATLAB files"
      ],
      "metadata": {
        "id": "vMS-yXVXkorz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import package\n",
        "import scipy.io\n",
        "\n",
        "# Load MATLAB file: mat\n",
        "file = 'albeck_gene_expression.mat'\n",
        "mat = scipy.io.loadmat(file)\n",
        "\n",
        "# Print the datatype type of mat\n",
        "print(type(mat))"
      ],
      "metadata": {
        "id": "13Xm8qRrjJRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the keys of the MATLAB dictionary\n",
        "print(mat.keys())\n",
        "\n",
        "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
        "print(type(mat['CYratioCyt']))\n",
        "\n",
        "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
        "print(np.shape(mat['CYratioCyt']))\n",
        "\n",
        "# Subset the array and plot it\n",
        "data = mat['CYratioCyt'][25, 5:]\n",
        "fig = plt.figure()\n",
        "plt.plot(data)\n",
        "plt.xlabel('time (min.)')\n",
        "plt.ylabel('normalized fluorescence (measure of expression)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P3aGfLb3jJN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to relational databases"
      ],
      "metadata": {
        "id": "ryr3bzcSl8jS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFf7lR_ts0vE"
      },
      "outputs": [],
      "source": [
        "# Import necessary module\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary module\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Save the table names to a list: table_names\n",
        "table_names = engine.table_names()\n",
        "\n",
        "# Print the table names to the shell\n",
        "print(table_names)\n"
      ],
      "metadata": {
        "id": "d9_HcuuUtHQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Querying relational databases in Python"
      ],
      "metadata": {
        "id": "PjORboH2t21i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Open engine connection: con\n",
        "con = engine.connect()\n",
        "\n",
        "# Perform query: rs\n",
        "rs = con.execute('select * from Album')\n",
        "\n",
        "# Save results of the query to DataFrame: df\n",
        "df = pd.DataFrame(rs.fetchall())\n",
        "\n",
        "# Close connection\n",
        "con.close()\n",
        "\n",
        "# Print head of DataFrame df\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "lPvjk64jtHMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open engine in context manager\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute('select LastName, Title from Employee')\n",
        "    df = pd.DataFrame(rs.fetchmany(size = 3))\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print the length of the DataFrame df\n",
        "print(len(df))\n",
        "\n",
        "# Print the head of the DataFrame df\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "xcN5zAN8tG77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Open engine in context manager\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute('select * from Employee where EmployeeId >= 6')\n",
        "    df = pd.DataFrame(rs.fetchall())\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print the head of the DataFrame df\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "Bk5xF5qPoqaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Open engine in context manager\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"select * from Employee order by BirthDate\")\n",
        "    df = pd.DataFrame(rs.fetchall())\n",
        "\n",
        "    # Set the DataFrame's column names\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "r7x9W22MpGdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Execute query and store records in DataFrame: df\n",
        "df = pd.read_sql_query('select * from Album', engine)\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Open engine in context manager and store query result in df1\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"SELECT * FROM Album\")\n",
        "    df1 = pd.DataFrame(rs.fetchall())\n",
        "    df1.columns = rs.keys()\n",
        "\n",
        "# Confirm that both methods yield the same result\n",
        "print(df.equals(df1))"
      ],
      "metadata": {
        "id": "4oE-ctgVprB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Execute query and store records in DataFrame: df\n",
        "df = pd.read_sql_query('select * from Employee where EmployeeId >= 6 order by BirthDate', engine)\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "KOt5U-hEpq8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open engine in context manager\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"SELECT Title, Name FROM Album INNER JOIN Artist on Album.ArtistID = Artist.ArtistID\")\n",
        "    df = pd.DataFrame(rs.fetchall())\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print head of DataFrame df\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "m1kjxjjnpq0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute query and store records in DataFrame: df\n",
        "df = pd.read_sql_query(\n",
        "    \"SELECT * FROM PlaylistTrack INNER JOIN Track ON PlaylistTrack.TrackId = Track.TrackId WHERE Milliseconds < 250000\",\n",
        "    engine\n",
        ")\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "fCByJ-sOsmCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}